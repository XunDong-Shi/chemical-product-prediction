{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(file_path,all_data):\n",
    "    pd_time=pd.read_csv(file_path+'/'+'Z230进口硫酸压力-Raw.csv',header=\"infer\",encoding='gbk',index_col=False)\n",
    "    pd_time.columns = [\"Id\", \"Time\", 'Value']\n",
    "    pd_time['Time']=pd_time['Time'].str.replace('[','').str.replace(']','')\n",
    "    pd_time['Time']=pd.to_datetime(pd_time['Time'])\n",
    "    for file in files:\n",
    "        data=pd.read_csv(file_path+'/'+file,header=\"infer\",encoding='gbk')\n",
    "        file_name=file.strip('-Raw.csv')\n",
    "        data.columns = [\"id\", \"Time\", file_name]\n",
    "        all_data=all_data.append(data[file_name])\n",
    "    trans_data=all_data.T\n",
    "    all_data=pd.concat([pd_time,trans_data],axis=1).drop(['Id','Value'],axis=1).set_index('Time')\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_April_path='/Mine/new/生产参数记录表（固定时间间隔）-2018年4月'\n",
    "x_May_path='/Mine/new/生产参数记录表（固定时间间隔）-2018年5月'\n",
    "files=[ 'Z230进口硫酸压力-Raw.csv','Z230进口液氨压力-Raw.csv','Z230进口液氨流量-Raw.csv','Z230进口洗涤液压力-Raw.csv',\n",
    "        'Z230进口洗涤液浓度-Raw.csv','成品重量-Raw.csv', '返料重量-Raw.csv','Z221进口液氨流量-Raw.csv',\n",
    "        'Z220造粒机电流-Raw.csv',\n",
    "        'F101鼓风机电流-Raw.csv', 'E301干燥窑转速-Raw.csv','E301干燥窑电流-Raw.csv','E301干燥窑进口烟气温度-Raw.csv',\n",
    "        'F101热风炉炉膛温度-Raw.csv','F101热风炉鼓风压力-Raw.csv','L101斗提机电流-Raw.csv','S101A振网筛电流-Raw.csv',\n",
    "        'S101B振网筛电流-Raw.csv','S102A破碎机电流1-Raw.csv','S102A破碎机电流2-Raw.csv','S102B破碎机电流1-Raw.csv',\n",
    "        'S102B破碎机电流2-Raw.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data=pd.DataFrame()\n",
    "all_April_data=read_data(x_April_path,all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data=pd.DataFrame()\n",
    "all_May_data=read_data(x_May_path,all_data)\n",
    "all_x_data=pd.concat([all_April_data,all_May_data],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征构造及数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_x_data['返料比']=all_x_data['返料重量']/all_x_data['成品重量']\n",
    "all_x_data['总压力']=all_x_data['Z230进口洗涤液压力']+all_x_data['Z230进口液氨压力']+all_x_data['Z230进口硫酸压力']\n",
    "all_x_data['含氮量']=all_x_data['Z230进口液氨压力']/all_x_data['总压力']\n",
    "all_x_data['含磷量']=all_x_data['Z230进口洗涤液压力']/all_x_data['总压力']\n",
    "all_x_data['硫酸量']=all_x_data['Z230进口硫酸压力']/all_x_data['总压力']\n",
    "all_x_data['中和度']=all_x_data['Z230进口洗涤液压力']/all_x_data['Z230进口液氨压力']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "April_y_data=pd.read_csv('/home/data/2.产品检验报告/产品检验报告2018-4-1.csv')\n",
    "May_y_data=pd.read_csv('/home/data/2.产品检验报告/产品检验报告2018-5-1-sample.csv')\n",
    "y_data=pd.concat([April_y_data,May_y_data],axis=0,sort=True)\n",
    "y_data=pd.concat([y_data, pd.DataFrame(columns=['0_time','1_time','2_time'])],sort=True)\n",
    "y_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(y_data)):\n",
    "    sp_str=y_data['product_batch'][i].split(' ')\n",
    "    ssp_str_0=sp_str[1].split(':')\n",
    "    ssp_str_1=sp_str[3].split(':')\n",
    "    if int(ssp_str_0[0])>int(ssp_str_1[0]):\n",
    "        ssp_str_1[0]=int(ssp_str_1[0])+23\n",
    "    else:\n",
    "        ssp_str_1[0]=int(ssp_str_1[0])-1\n",
    "    y_data['0_time'][i]=str(2018.)+sp_str[0] + ' ' + ssp_str_0[0] + ':00'+':00'\n",
    "    y_data['2_time'][i]=str(2018.)+sp_str[0]+' '+str(ssp_str_1[0])+':59'+':59' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_data['0_time']=pd.to_datetime(y_data['0_time'],format='%Y.%m.%d %H:%M:%S')\n",
    "y_data['2_time']=pd.to_datetime(y_data['2_time'],format='%Y.%m.%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "re_x=pd.DataFrame()\n",
    "std_x=pd.DataFrame()\n",
    "for j in range(1,len(y_data)):#\n",
    "    start=y_data['0_time'][j]-pd.Timedelta(\"7 Hours\")\n",
    "    end=y_data['2_time'][j]-pd.Timedelta(\"7 Hours\")\n",
    "    resample=all_x_data[start:end]\n",
    "    drop_index=resample[(resample['成品重量']<=5)|(resample['返料重量']<=50)].index\n",
    "    clean_data=resample.drop(index=drop_index)\n",
    "    sample=pd.DataFrame(clean_data[start:end].mean()).T\n",
    "    sample['Time']=start+pd.Timedelta(\"7 Hours\")\n",
    "    sample.index=[j-1]\n",
    "    re_x=re_x.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_data=y_data[['nitrogen_content','phosphorus_content','total_nutrient','water_content','particle_size']][0:143]\n",
    "per_x_data=pd.concat([re_x,add_data],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_use_columns=['Z230进口液氨流量','Z220造粒机电流','F101鼓风机电流','E301干燥窑电流','F101热风炉鼓风压力',\n",
    "                 'S101A振网筛电流','S101B振网筛电流','E301干燥窑转速','S102A破碎机电流1','S102A破碎机电流2',\n",
    "                 'S102B破碎机电流1','S102B破碎机电流2','Z230进口液氨压力', 'Z221进口液氨流量','返料比', '总压力',\n",
    "                 '含氮量', '含磷量', '中和度','硫酸量','E301干燥窑进口烟气温度','F101热风炉炉膛温度',\n",
    "                 'nitrogen_content', 'phosphorus_content', 'total_nutrient','water_content','particle_size']\n",
    "scaled_x=per_x_data[all_use_columns]/per_x_data[all_use_columns].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1_cols=[ 'Z221进口液氨流量','Z220造粒机电流', 'E301干燥窑电流', 'F101热风炉鼓风压力','返料比',\n",
    "         '总压力', '含氮量', '含磷量', '中和度', '硫酸量','nitrogen_content','E301干燥窑进口烟气温度']\n",
    "x2_cols=['Z221进口液氨流量','Z220造粒机电流','E301干燥窑电流', 'F101热风炉鼓风压力','返料比',\n",
    "         '总压力', '含氮量', '含磷量', '中和度', '硫酸量','phosphorus_content','E301干燥窑进口烟气温度']\n",
    "x3_cols=[ 'Z221进口液氨流量','Z220造粒机电流','E301干燥窑电流', 'F101热风炉鼓风压力','返料比',\n",
    "         '总压力', '含氮量', '含磷量', '中和度', '硫酸量','total_nutrient','E301干燥窑进口烟气温度']\n",
    "x4_cols=[ 'Z221进口液氨流量','Z220造粒机电流','E301干燥窑电流', 'F101热风炉鼓风压力','返料比',\n",
    "         '总压力', '含氮量', '含磷量', '中和度', '硫酸量','water_content','E301干燥窑进口烟气温度']\n",
    "x5_cols=['S102A破碎机电流1','返料比','总压力', '含氮量','含磷量','中和度','硫酸量','E301干燥窑进口烟气温度']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1=scaled_x[x1_cols][0:143].values\n",
    "x2=scaled_x[x2_cols][0:143].values\n",
    "x3=scaled_x[x3_cols][0:143].values\n",
    "x4=scaled_x[x4_cols][0:143].values\n",
    "x5=scaled_x[x5_cols][37:143].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "per_y_data=y_data[['nitrogen_content','phosphorus_content','total_nutrient','water_content','particle_size']][1:144]\n",
    "per_y_data.columns = [\"y1\", \"y2\", 'y3','y4','y5']\n",
    "per_y_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1=per_y_data['y1'][0:143].values\n",
    "y2=per_y_data['y2'][0:143].values\n",
    "y3=per_y_data['y3'][0:143].values\n",
    "y4=per_y_data['y4'][0:143].values\n",
    "y5=per_y_data['y5'][37:143].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "class stacking(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self,mod,meta_model):\n",
    "        self.mod = mod\n",
    "        self.meta_model = meta_model\n",
    "        self.kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.saved_model = [list() for i in self.mod]\n",
    "        oof_train = np.zeros((X.shape[0], len(self.mod)))\n",
    "        \n",
    "        for i,model in enumerate(self.mod):\n",
    "            for train_index, val_index in self.kf.split(X,y):\n",
    "                renew_model = clone(model)\n",
    "                renew_model.fit(X[train_index], y[train_index])\n",
    "                self.saved_model[i].append(renew_model)\n",
    "                oof_train[val_index,i] = renew_model.predict(X[val_index])      \n",
    "        self.meta_model.fit(oof_train,y)\n",
    "        return self\n",
    "   \n",
    "    def predict(self,X):\n",
    "        whole_test = np.column_stack([np.column_stack(model.predict(X) for model in single_model).mean(axis=1) \n",
    "                                      for single_model in self.saved_model]) \n",
    "        return self.meta_model.predict(whole_test)\n",
    "    \n",
    "    def get_oof(self,X,y,test_X):\n",
    "        oof = np.zeros((X.shape[0],len(self.mod)))\n",
    "        test_single = np.zeros((test_X.shape[0],5))\n",
    "        test_mean = np.zeros((test_X.shape[0],len(self.mod)))\n",
    "        for i,model in enumerate(self.mod):\n",
    "            for j, (train_index,val_index) in enumerate(self.kf.split(X,y)):\n",
    "                clone_model = clone(model)\n",
    "                clone_model.fit(X[train_index],y[train_index])\n",
    "                oof[val_index,i] = clone_model.predict(X[val_index])\n",
    "                test_single[:,j] = clone_model.predict(test_X)\n",
    "            test_mean[:,i] = test_single.mean(axis=1)\n",
    "        return oof, test_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knr_1=KernelRidge()\n",
    "ela_1=ElasticNet(alpha=5e-05,l1_ratio=0.8,max_iter=10000)\n",
    "gbr_1= GradientBoostingRegressor(learning_rate=0.1, max_depth=1, n_estimators=80)\n",
    "xg_1=XGBRegressor(learning_rate=0.2, max_depth=1, n_estimators=40)\n",
    "svr_1=SVR(C=100, gamma=0.1, kernel='rbf')\n",
    "stack_model_1 = stacking(mod=[ela_1,gbr_1,xg_1,svr_1],meta_model=knr_1)\n",
    "stack_model_1.fit(x1,y1)\n",
    "for m in range(142,220):\n",
    "    if m<143:   \n",
    "        test_x1=scaled_x[x1_cols][m:m+1].values\n",
    "        test_y=stack_model_1.predict(test_x1).tolist()\n",
    "        scaled_x.loc[m+1,'nitrogen_content']=round(test_y[0],2)\n",
    "    else:    \n",
    "        test_x1=scaled_x[x1_cols][m:m+1].values\n",
    "        test_x1[0][10]=test_x1[0][10]/16.3\n",
    "        test_y=stack_model_1.predict(test_x1).tolist()\n",
    "        scaled_x.loc[m+1,'nitrogen_content']=test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knr_2=KernelRidge()\n",
    "ela_2=ElasticNet(alpha= 5e-05, l1_ratio= 0.8, max_iter= 10000)\n",
    "gbr_2= GradientBoostingRegressor(learning_rate= 0.05, max_depth= 4, n_estimators= 40)\n",
    "xg_2=XGBRegressor(learning_rate= 0.1, max_depth= 1, n_estimators= 80)\n",
    "svr_2=SVR(C= 10, gamma= 0.5, kernel= 'rbf')\n",
    "stack_model_2 = stacking(mod=[ela_2,gbr_2,xg_2,svr_2],meta_model=knr_2)\n",
    "stack_model_2.fit(x2,y2)\n",
    "for m in range(142,220):\n",
    "    if m<143:   \n",
    "        test_x2=scaled_x[x2_cols][m:m+1].values\n",
    "        test_y=stack_model_2.predict(test_x2).tolist()\n",
    "        scaled_x.loc[m+1,'phosphorus_content']=round(test_y[0],2)\n",
    "    else:    \n",
    "        test_x2=scaled_x[x2_cols][m:m+1].values\n",
    "        test_x2[0][10]=test_x2[0][10]/44.47\n",
    "        test_y=stack_model_2.predict(test_x2).tolist()\n",
    "        scaled_x.loc[m+1,'phosphorus_content']=test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knr_3=KernelRidge()\n",
    "ela_3=ElasticNet(alpha= 5e-05, l1_ratio= 0.8, max_iter= 10000)\n",
    "gbr_3= GradientBoostingRegressor(learning_rate= 0.02, max_depth= 3, n_estimators= 100)\n",
    "xg_3=XGBRegressor(learning_rate= 0.1, max_depth= 1, n_estimators= 80)\n",
    "svr_3=SVR(C= 10, gamma= 0.1, kernel= 'rbf')\n",
    "stack_model_3 = stacking(mod=[ela_3,gbr_3,xg_3,svr_3],meta_model=knr_3)\n",
    "stack_model_3.fit(x3,y3)\n",
    "for m in range(142,220):\n",
    "    if m<143:   \n",
    "        test_x3=scaled_x[x3_cols][m:m+1].values\n",
    "        test_y=stack_model_3.predict(test_x3).tolist()\n",
    "        scaled_x.loc[m+1,'total_nutrient']=round(test_y[0],2)\n",
    "    else:    \n",
    "        test_x3=scaled_x[x3_cols][m:m+1].values\n",
    "        test_x3[0][10]=test_x3[0][10]/60.792\n",
    "        test_y=stack_model_3.predict(test_x3).tolist()\n",
    "        scaled_x.loc[m+1,'total_nutrient']=test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knr_4=KernelRidge()\n",
    "ela_4=ElasticNet(alpha= 5e-05, l1_ratio= 0.8, max_iter= 10000)\n",
    "gbr_4= GradientBoostingRegressor(learning_rate= 0.1, max_depth= 1, n_estimators= 60)\n",
    "xg_4=XGBRegressor(learning_rate= 0.05, max_depth= 1, n_estimators= 200)\n",
    "svr_4=SVR(C= 1, gamma= 0.5, kernel= 'rbf')\n",
    "stack_model_4 = stacking(mod=[ela_4,gbr_4,xg_4,svr_4],meta_model=knr_4)\n",
    "stack_model_4.fit(x4,y4)\n",
    "for m in range(142,220):\n",
    "    if m<143:   \n",
    "        test_x4=scaled_x[x4_cols][m:m+1].values\n",
    "        test_y=stack_model_4.predict(test_x4).tolist()\n",
    "        scaled_x.loc[m+1,'water_content']=round(test_y[0],2)\n",
    "    else:    \n",
    "        test_x4=scaled_x[x4_cols][m:m+1].values\n",
    "        test_x4[0][10]=test_x4[0][10]/2.798\n",
    "        test_y=stack_model_4.predict(test_x4).tolist()\n",
    "        scaled_x.loc[m+1,'water_content']=test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knr_5=KernelRidge()\n",
    "ela_5=ElasticNet(alpha= 0.0005, l1_ratio= 0.8, max_iter= 10000)\n",
    "gbr_5= GradientBoostingRegressor(learning_rate= 0.1, max_depth= 2, n_estimators= 20)\n",
    "xg_5=XGBRegressor(learning_rate= 0.05, max_depth= 1, n_estimators= 200)\n",
    "svr_5=SVR(C= 100, gamma= 1, kernel= 'rbf')\n",
    "stack_model_5 = stacking(mod=[ela_5,gbr_5,xg_5,svr_5],meta_model=knr_5)\n",
    "stack_model_5.fit(x5,y5)\n",
    "for m in range(142,220): \n",
    "    test_x5=scaled_x[x5_cols][m:m+1].values\n",
    "    test_y=stack_model_5.predict(test_x5).tolist()\n",
    "    scaled_x.loc[m+1,'particle_size']=test_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结果输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_columns=['nitrogen_content','phosphorus_content','total_nutrient','water_content','particle_size']\n",
    "result=scaled_x[final_columns][143:220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output=pd.DataFrame({\"id\":id,\"phosphorus_content\":result['phosphorus_content'].values,\n",
    "                     \"nitrogen_content\":result['nitrogen_content'].values,\n",
    "                     'total_nutrient':result['total_nutrient'].values,\n",
    "                     'water_content':result['water_content'].values,\n",
    "                     'particle_size':result['particle_size'].values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.set_index('id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.to_csv('/home/code/result.csv',encoding='UTF-8')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
